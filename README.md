## ETL Pipeline Automation on US Store Sales Report
## Description
Developing  an automated data pipeline system (ETL) by combining Apache Airflow for orchestration, PySpark for data transformation, and loading  transformed data into a MongoDB database.  This process is scheduled to run every Saturday between 09:10 and 09:30 with a 10-minute interval. Followed by data validation using Great Expectations.

## Prerequisites
-- Python 3.x
-- Apache Airflow
-- Apache PySpark
