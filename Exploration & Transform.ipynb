{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n=================================================\\nMilestone 3\\n\\nNama  : Mirza Rendra Sjarief\\nBatch : CODA-001-RMT\\n\\nProgram ini dibuat untuk melakukan data explorasi sederhana menggunakan Pandas DataFrame \\nyang dilanjutkan dengan transform dataset menggunakan PySpark. Adapun dataset yang dipakai adalah \\ndataset tentang Us Store Sales selama periode tahun 2010 - 2011\\n\\n=================================================\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "=================================================\n",
    "Milestone 3\n",
    "\n",
    "Nama  : Mirza Rendra Sjarief\n",
    "Batch : CODA-001-RMT\n",
    "\n",
    "Program ini dibuat untuk melakukan data explorasi sederhana menggunakan Pandas DataFrame \n",
    "yang dilanjutkan dengan transform dataset menggunakan PySpark. Adapun dataset yang dipakai adalah \n",
    "dataset tentang Us Store Sales selama periode tahun 2010 - 2011\n",
    "\n",
    "=================================================\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, concat, lit, when, to_date, to_timestamp, upper, lower, date_format,concat_ws,hash,abs,monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas DataFrame Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sebelum melakukan transformasi data dengan Pyspark. dataset ini akan melalui proses pengecekan atau eksplorasi data dengan menggunakan Library Pandas DataFrame, karena lebih flexibel dan memiliki fitur yang sedikit lebih lengkap dibandingkan dengan pyspark dalam hal explorasi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area Code</th>\n",
       "      <th>State</th>\n",
       "      <th>Market</th>\n",
       "      <th>Market Size</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Sales</th>\n",
       "      <th>COGS</th>\n",
       "      <th>Total Expenses</th>\n",
       "      <th>Marketing</th>\n",
       "      <th>Inventory</th>\n",
       "      <th>Budget Profit</th>\n",
       "      <th>Budget COGS</th>\n",
       "      <th>Budget Margin</th>\n",
       "      <th>Budget Sales</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Date</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Product</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>East</td>\n",
       "      <td>Small Market</td>\n",
       "      <td>107.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>962.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>2</td>\n",
       "      <td>04/01/10 00:00:00</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>Columbian</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>East</td>\n",
       "      <td>Small Market</td>\n",
       "      <td>75.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>2</td>\n",
       "      <td>07/01/10 00:00:00</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>Columbian</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>East</td>\n",
       "      <td>Small Market</td>\n",
       "      <td>122.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11/01/10 00:00:00</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>Columbian</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>East</td>\n",
       "      <td>Small Market</td>\n",
       "      <td>105.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12/01/10 00:00:00</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>Columbian</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>East</td>\n",
       "      <td>Small Market</td>\n",
       "      <td>104.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>2</td>\n",
       "      <td>07/01/11 00:00:00</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>Columbian</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Area Code        State Market   Market Size  Profit  Margin  Sales   COGS  \\\n",
       "0        203  Connecticut   East  Small Market   107.0   176.0  292.0  116.0   \n",
       "1        203  Connecticut   East  Small Market    75.0   135.0  225.0   90.0   \n",
       "2        203  Connecticut   East  Small Market   122.0   195.0  325.0  130.0   \n",
       "3        203  Connecticut   East  Small Market   105.0   174.0  289.0  115.0   \n",
       "4        203  Connecticut   East  Small Market   104.0   135.0  223.0   90.0   \n",
       "\n",
       "   Total Expenses  Marketing  Inventory  Budget Profit  Budget COGS  \\\n",
       "0            69.0       38.0      962.0          110.0        110.0   \n",
       "1            60.0       29.0     1148.0           90.0         80.0   \n",
       "2            73.0       42.0     1134.0          130.0        110.0   \n",
       "3            69.0       37.0     1166.0          110.0        100.0   \n",
       "4            56.0       29.0     1148.0           90.0         80.0   \n",
       "\n",
       "   Budget Margin  Budget Sales  ProductId               Date Product Type  \\\n",
       "0          160.0         270.0          2  04/01/10 00:00:00       Coffee   \n",
       "1          130.0         210.0          2  07/01/10 00:00:00       Coffee   \n",
       "2          180.0         290.0          2  11/01/10 00:00:00       Coffee   \n",
       "3          160.0         260.0          2  12/01/10 00:00:00       Coffee   \n",
       "4          130.0         210.0          2  07/01/11 00:00:00       Coffee   \n",
       "\n",
       "     Product     Type  \n",
       "0  Columbian  Regular  \n",
       "1  Columbian  Regular  \n",
       "2  Columbian  Regular  \n",
       "3  Columbian  Regular  \n",
       "4  Columbian  Regular  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading dataset to Pandas DataFrame\n",
    "df = pd.read_csv('/Users/mac/Documents/Hacktiv8/M3/p2-coda001-rmt-m3-mirzasjarief/us_store_sales.csv', low_memory=False)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Berikut adalah background dataset yang diguanakan :\n",
    "\n",
    "- Source    : kaggle.com\n",
    "- URL       : https://www.kaggle.com/datasets/dsfelix/us-stores-sales\n",
    "- Author    : Ds Felix\n",
    "- Licence   : CC0: Public Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing summarizing diplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Langkah pertama adalah melakukan pengecekan duplikat data, hasil menunjukan tidak adanya data duplikat pada dataset ini sehingga bisa dilakukan tahap pengecekan selanjutnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Inventory</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Sales</th>\n",
       "      <th>COGS</th>\n",
       "      <th>Total Expenses</th>\n",
       "      <th>Marketing</th>\n",
       "      <th>Budget Sales</th>\n",
       "      <th>Budget Profit</th>\n",
       "      <th>Budget COGS</th>\n",
       "      <th>Budget Margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4248.000000</td>\n",
       "      <td>4248.000000</td>\n",
       "      <td>4248.000000</td>\n",
       "      <td>4248.000000</td>\n",
       "      <td>4248.000000</td>\n",
       "      <td>4248.000000</td>\n",
       "      <td>4248.000000</td>\n",
       "      <td>4248.000000</td>\n",
       "      <td>4248.000000</td>\n",
       "      <td>4248.000000</td>\n",
       "      <td>4248.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>582.278013</td>\n",
       "      <td>749.381356</td>\n",
       "      <td>6.887006</td>\n",
       "      <td>192.987524</td>\n",
       "      <td>84.433145</td>\n",
       "      <td>54.063559</td>\n",
       "      <td>31.185028</td>\n",
       "      <td>175.649718</td>\n",
       "      <td>60.913371</td>\n",
       "      <td>74.830508</td>\n",
       "      <td>100.819209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>221.140310</td>\n",
       "      <td>661.031896</td>\n",
       "      <td>3.664072</td>\n",
       "      <td>151.133127</td>\n",
       "      <td>67.249769</td>\n",
       "      <td>32.352598</td>\n",
       "      <td>27.023264</td>\n",
       "      <td>148.891522</td>\n",
       "      <td>79.546123</td>\n",
       "      <td>66.238145</td>\n",
       "      <td>92.602725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>203.000000</td>\n",
       "      <td>-3534.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-320.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>417.000000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>573.000000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>772.000000</td>\n",
       "      <td>910.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>985.000000</td>\n",
       "      <td>8252.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>912.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>1140.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Area Code    Inventory    ProductId        Sales         COGS  \\\n",
       "count  4248.000000  4248.000000  4248.000000  4248.000000  4248.000000   \n",
       "mean    582.278013   749.381356     6.887006   192.987524    84.433145   \n",
       "std     221.140310   661.031896     3.664072   151.133127    67.249769   \n",
       "min     203.000000 -3534.000000     1.000000    17.000000     0.000000   \n",
       "25%     417.000000   432.000000     4.000000   100.000000    43.000000   \n",
       "50%     573.000000   619.000000     6.000000   138.000000    60.000000   \n",
       "75%     772.000000   910.500000    10.000000   230.000000   100.000000   \n",
       "max     985.000000  8252.000000    13.000000   912.000000   364.000000   \n",
       "\n",
       "       Total Expenses    Marketing  Budget Sales  Budget Profit  Budget COGS  \\\n",
       "count     4248.000000  4248.000000   4248.000000    4248.000000  4248.000000   \n",
       "mean        54.063559    31.185028    175.649718      60.913371    74.830508   \n",
       "std         32.352598    27.023264    148.891522      79.546123    66.238145   \n",
       "min         10.000000     0.000000      0.000000    -320.000000     0.000000   \n",
       "25%         33.000000    13.000000     80.000000      20.000000    30.000000   \n",
       "50%         46.000000    22.000000    130.000000      40.000000    50.000000   \n",
       "75%         65.000000    39.000000    210.000000      80.000000    90.000000   \n",
       "max        190.000000   156.000000   1140.000000     560.000000   450.000000   \n",
       "\n",
       "       Budget Margin  \n",
       "count    4248.000000  \n",
       "mean      100.819209  \n",
       "std        92.602725  \n",
       "min      -210.000000  \n",
       "25%        50.000000  \n",
       "50%        70.000000  \n",
       "75%       130.000000  \n",
       "max       690.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing describe function\n",
    "df[['Area Code','Inventory','ProductId','Sales','COGS','Total Expenses','Marketing','Budget Sales','Budget Profit','Budget COGS','Budget Margin']].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Langkah selanjutnya adalah pengecekan angka negatif diluar dari column yang bersifat numerik atau yang bersifat perhitungan untuk menjaga konsistensi data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Inventory Column** menunjukan minimum value data angka negatif (-3534.000000), hal tersebut seharusnya tidak mungkin terjadi karena Inventaris negatif berarti ada lebih banyak produk yang dijual daripada yang tersedia secara fisik. Saat stok habis, nilai inventaris seharusnya menjadi nol, bukan menjadi negatif. Untuk menghindari analisa dan pengambilan keputusan yang salah, maka selanjutnya transformasi akan dilakukan dengan mengubah bentuk angka negatif menjadi = 0 menggunakan library Pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4248 entries, 0 to 4247\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Area Code       4248 non-null   int64  \n",
      " 1   State           4248 non-null   object \n",
      " 2   Market          4248 non-null   object \n",
      " 3   Market Size     4248 non-null   object \n",
      " 4   Profit          4248 non-null   float64\n",
      " 5   Margin          4248 non-null   float64\n",
      " 6   Sales           4248 non-null   float64\n",
      " 7   COGS            4248 non-null   float64\n",
      " 8   Total Expenses  4248 non-null   float64\n",
      " 9   Marketing       4248 non-null   float64\n",
      " 10  Inventory       4248 non-null   float64\n",
      " 11  Budget Profit   4248 non-null   float64\n",
      " 12  Budget COGS     4248 non-null   float64\n",
      " 13  Budget Margin   4248 non-null   float64\n",
      " 14  Budget Sales    4248 non-null   float64\n",
      " 15  ProductId       4248 non-null   int64  \n",
      " 16  Date            4248 non-null   object \n",
      " 17  Product Type    4248 non-null   object \n",
      " 18  Product         4248 non-null   object \n",
      " 19  Type            4248 non-null   object \n",
      "dtypes: float64(11), int64(2), object(7)\n",
      "memory usage: 663.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Computing data structure info\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selanjutnya adalah mengecek tipe data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Date Column** menunjukan tipe data object, hal ini akan menimbulkan kesulitan saat proses pengolahan dan penelitian karena adanya ketidak konsistenan data, contohnya apabila melakukan proses load data ke PostgresSQL, sehingga perlu dilakukan perubahan dari bentuk tipe data object menjadi tipe data date dengan menggunakan library Pyspark pada tahap transformasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area Code       156\n",
       "State            20\n",
       "Market            4\n",
       "ProductId        13\n",
       "Product Type      4\n",
       "Product          13\n",
       "Type              2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing nunique function\n",
    "df[['Area Code','State','Market','ProductId', 'Product Type','Product','Type']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kemudian mengecek kolom categorycal uniqe value pada dataset\n",
    "\n",
    "- **Column Area Code** memiliki uniqe number yang terlalu banyak yaitu total 156, yang akan menyulitkan dalam proses penelitian lanjutan seperti mencari kolerasi dan prediksi terutama jika data diubah menjadi format one-hot encoding. Selain itu sudah terdapat kolom State untuk menggambarkan area sehingga kolom Area Code akan dihapus pada proses transformasi dengan library Pyspark.\n",
    "\n",
    "- **Column Product** memiliki uniqe value dan fungsi yang kurang lebih sama dengan kolom ProductId, sehingga ekstistensi nya tidak diperlukan lagi karena sudah diwakilkan keberadaannya dengan ProductId, sehingga column Product akan dihapus pada proses transformasi dengan library Pyspark agar dataset lebih relevan dan efektif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profit</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Budget Profit</th>\n",
       "      <th>Budget Margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Profit  Margin  Sales  Budget Profit  Budget Margin\n",
       "0   107.0   176.0  292.0          110.0          160.0\n",
       "1    75.0   135.0  225.0           90.0          130.0\n",
       "2   122.0   195.0  325.0          130.0          180.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show column top 3 \n",
    "df[['Profit','Margin','Sales','Budget Profit','Budget Margin']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Langkah selanjutnya pengecekan data redundant\n",
    "\n",
    "-  **Column Profit** dan **Column Margin** merupakan turunan langsung dari column Sales, sama halnya dengan cost dan revenue, tidak menambah informasi baru tetapi hanya mencerminkan hubungan matematis antara fitur lainnya. Redundansi ini bisa membingungkan dalam analisis dan membuat dataset tidak efisien. Selanjutnya akan dihapus pada proses transformasi data menggunakan library Pyspark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Market Size</th>\n",
       "      <th>Market</th>\n",
       "      <th>Type</th>\n",
       "      <th>Product Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Small Market</td>\n",
       "      <td>East</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Small Market</td>\n",
       "      <td>East</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Small Market</td>\n",
       "      <td>East</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         State   Market Size Market     Type Product Type\n",
       "0  Connecticut  Small Market   East  Regular       Coffee\n",
       "1  Connecticut  Small Market   East  Regular       Coffee\n",
       "2  Connecticut  Small Market   East  Regular       Coffee"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show column with object data type\n",
    "df[['State','Market Size','Market','Type','Product Type']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Langkah selanjutnya adalah merubah huruf pada setiap baris pada kolom yang bertipe data object yang awalnya diawali dengan huruf kapital menjadi menjadi small letter, dengan tujuan menjaga konstistensi dan kebersihan data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Area Code', 'State', 'Market', 'Market Size', 'Profit', 'Margin',\n",
       "       'Sales', 'COGS', 'Total Expenses', 'Marketing', 'Inventory',\n",
       "       'Budget Profit', 'Budget COGS', 'Budget Margin', 'Budget Sales',\n",
       "       'ProductId', 'Date', 'Product Type', 'Product', 'Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Langkah terakhir agar menghasilkan data yang bersih dan tidak menimbulkan error (contohnya apabila di load ke PostgresSQL) adalah mengubah seluruh nama kolom dengan gabungan huruf kapital menjadi small letter dan mengganti spasi yang awalnya sebagai pemisah antar kata menjadi under score. Selain itu lebih umum digunakan oleh programmer juga kompatibel dengan berbagai alat dan bahasa pemrograman seperti Python, SQL, dan Spark translate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Summary of Data Exploration\n",
    "\n",
    "- Here are the facts, insights, and steps that need to be taken as a result of exploring us-store-sales dataset :\n",
    "\n",
    "- **Data Consistency and Stability:**\n",
    "\n",
    "- Object-type columns were standardized by converting all text to lowercase to ensure consistency, data cleanliness, and prevent errors in queries or joins caused by case sensitivity.\n",
    "\n",
    "- Column names were formatted in lowercase with underscores to improve consistency, compatibility, and ease of management, In addition, it is more commonly used by programmers and is also compatible with various tools and programming languages such as Python, SQL, and Spark.\n",
    "\n",
    "- **Column Redundancy:**\n",
    "\n",
    "- Profit and Margin columns, derived directly from Sales, do not provide new information and only reflect mathematical relationships. These will be removed during transformation using PySpark to simplify the dataset.\n",
    "\n",
    "- **High Cardinality Issue:**\n",
    "\n",
    "- The Area Code column contains too many unique values, which complicates advanced analysis (e.g., correlation or prediction). Its role is already represented by the State column, so it will be dropped during transformation.\n",
    "\n",
    "- **Duplicate Information:**\n",
    "\n",
    "- The Product column is redundant as its role is covered by ProductId. It will also be removed during the transformation process to enhance dataset efficiency.\n",
    "\n",
    "- **Invalid Inventory Values:**\n",
    "\n",
    "- The Inventory column includes negative values (e.g., -3534), which are unrealistic since inventory cannot be negative. Negative values will be corrected to 0 during transformation to avoid inaccurate analysis.\n",
    "\n",
    "- **Date Format Inconsistency:**\n",
    "\n",
    "- The Date column is stored as an object type, which may cause issues during processing, especially in databases like PostgreSQL. It will be converted to a date type using PySpark during the transformation phase for consistency and usability.\n",
    "\n",
    "\n",
    "- This preparation ensures the dataset is clean, efficient, and ready for further analysis or machine learning tasks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Google Slide Presentation : https://docs.google.com/presentation/d/1tWFU8cy0lXD5c1AtrZStEPrXmw9MVlt0eueMK0YqbL0/edit#slide=id.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark Data Cleaning and Transformation Procces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/usr/local/spark/./bin/spark-submit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# configure and create a new SparkSession instance.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m spark\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pyspark/sql/session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pyspark/context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pyspark/context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m     )\n\u001b[0;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    204\u001b[0m         master,\n\u001b[1;32m    205\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[1;32m    216\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pyspark/context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[0;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pyspark/java_gateway.py:97\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, signal\u001b[38;5;241m.\u001b[39mSIG_IGN)\n\u001b[1;32m     96\u001b[0m     popen_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreexec_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m preexec_func\n\u001b[0;32m---> 97\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# preexec_fn not supported on Windows\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     proc \u001b[38;5;241m=\u001b[39m Popen(command, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_kwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/subprocess.py:1953\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1951\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[1;32m   1952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1955\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/local/spark/./bin/spark-submit'"
     ]
    }
   ],
   "source": [
    "# configure and create a new SparkSession instance.\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Membuat atau Mengakses SparkSession: Jika belum ada sesi Spark yang aktif, fungsi ini akan membuat sesi Spark baru, dan apabila sudah ada sesi aktif, fungsi ini akan mengembalikan sesi yang sudah ada dengan tujuan memastikan hanya satu instance SparkSession yang aktif dalam satu aplikasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------+------------+------+------+-----+-----+--------------+---------+---------+-------------+-----------+-------------+------------+---------+-----------------+------------+-----------+-------+\n",
      "|Area Code|      State|Market| Market Size|Profit|Margin|Sales| COGS|Total Expenses|Marketing|Inventory|Budget Profit|Budget COGS|Budget Margin|Budget Sales|ProductId|             Date|Product Type|    Product|   Type|\n",
      "+---------+-----------+------+------------+------+------+-----+-----+--------------+---------+---------+-------------+-----------+-------------+------------+---------+-----------------+------------+-----------+-------+\n",
      "|      203|Connecticut|  East|Small Market| 107.0| 176.0|292.0|116.0|          69.0|     38.0|    962.0|        110.0|      110.0|        160.0|       270.0|        2|04/01/10 00:00:00|      Coffee|  Columbian|Regular|\n",
      "|      203|Connecticut|  East|Small Market|  75.0| 135.0|225.0| 90.0|          60.0|     29.0|   1148.0|         90.0|       80.0|        130.0|       210.0|        2|07/01/10 00:00:00|      Coffee|  Columbian|Regular|\n",
      "|      203|Connecticut|  East|Small Market| 122.0| 195.0|325.0|130.0|          73.0|     42.0|   1134.0|        130.0|      110.0|        180.0|       290.0|        2|11/01/10 00:00:00|      Coffee|  Columbian|Regular|\n",
      "|      203|Connecticut|  East|Small Market| 105.0| 174.0|289.0|115.0|          69.0|     37.0|   1166.0|        110.0|      100.0|        160.0|       260.0|        2|12/01/10 00:00:00|      Coffee|  Columbian|Regular|\n",
      "|      203|Connecticut|  East|Small Market| 104.0| 135.0|223.0| 90.0|          56.0|     29.0|   1148.0|         90.0|       80.0|        130.0|       210.0|        2|07/01/11 00:00:00|      Coffee|  Columbian|Regular|\n",
      "|      203|Connecticut|  East|Small Market| 104.0| 135.0|223.0| 90.0|          56.0|     29.0|   1139.0|         90.0|       80.0|        130.0|       210.0|        2|08/01/11 00:00:00|      Coffee|  Columbian|Regular|\n",
      "|      203|Connecticut|  East|Small Market| 135.0| 155.0|275.0|103.0|          64.0|     33.0|   1130.0|        110.0|       90.0|        150.0|       240.0|        2|09/01/11 00:00:00|      Coffee|  Columbian|Regular|\n",
      "|      203|Connecticut|  East|Small Market| 171.0| 188.0|334.0|125.0|          73.0|     41.0|   1119.0|        130.0|      100.0|        160.0|       260.0|        2|10/01/11 00:00:00|      Coffee|  Columbian|Regular|\n",
      "|      203|Connecticut|  East|Small Market| 181.0| 195.0|346.0|130.0|          73.0|     42.0|   1134.0|        130.0|      110.0|        180.0|       290.0|        2|11/01/11 00:00:00|      Coffee|  Columbian|Regular|\n",
      "|      203|Connecticut|  East|Small Market|  15.0|  31.0| 51.0| 20.0|          16.0|      5.0|    804.0|         20.0|       20.0|         30.0|        50.0|       13|06/01/10 00:00:00|         Tea|  Green Tea|Regular|\n",
      "|      203|Connecticut|  East|Small Market|  33.0|  54.0| 90.0| 36.0|          21.0|     10.0|    809.0|         40.0|       30.0|         60.0|        90.0|       13|11/01/10 00:00:00|         Tea|  Green Tea|Regular|\n",
      "|      203|Connecticut|  East|Small Market|  17.0|  28.0| 47.0| 19.0|          15.0|      5.0|    811.0|         20.0|       20.0|         30.0|        50.0|       13|08/01/11 00:00:00|         Tea|  Green Tea|Regular|\n",
      "|      203|Connecticut|  East|Small Market|  27.0|  36.0| 64.0| 24.0|          18.0|      6.0|    806.0|         40.0|       20.0|         40.0|        60.0|       13|10/01/11 00:00:00|         Tea|  Green Tea|Regular|\n",
      "|      203|Connecticut|  East|Small Market|  49.0|  54.0| 96.0| 36.0|          21.0|     10.0|    809.0|         40.0|       30.0|         60.0|        90.0|       13|11/01/11 00:00:00|         Tea|  Green Tea|Regular|\n",
      "|      203|Connecticut|  East|Small Market|  -2.0|  75.0|128.0| 53.0|          77.0|     48.0|    597.0|         10.0|       50.0|         70.0|       120.0|        5|06/01/10 00:00:00|    Espresso|Caffe Mocha|Regular|\n",
      "|      203|Connecticut|  East|Small Market|   1.0|  84.0|144.0| 60.0|          83.0|     54.0|    606.0|         40.0|       40.0|         90.0|       130.0|        5|10/01/10 00:00:00|    Espresso|Caffe Mocha|Regular|\n",
      "|      203|Connecticut|  East|Small Market|   2.0|  86.0|147.0| 61.0|          84.0|     55.0|    613.0|         10.0|       60.0|         80.0|       140.0|        5|11/01/10 00:00:00|    Espresso|Caffe Mocha|Regular|\n",
      "|      203|Connecticut|  East|Small Market|  11.0| 105.0|201.0| 75.0|         103.0|     68.0|    522.0|         20.0|       70.0|        100.0|       170.0|        5|01/01/11 00:00:00|    Espresso|Caffe Mocha|Regular|\n",
      "|      203|Connecticut|  East|Small Market|   4.0|  90.0|165.0| 65.0|          87.0|     58.0|    513.0|         20.0|       60.0|         90.0|       150.0|        5|02/01/11 00:00:00|    Espresso|Caffe Mocha|Regular|\n",
      "|      203|Connecticut|  East|Small Market|   0.0|  87.0|160.0| 63.0|          87.0|     57.0|    506.0|         10.0|       60.0|         80.0|       140.0|        5|03/01/11 00:00:00|    Espresso|Caffe Mocha|Regular|\n",
      "+---------+-----------+------+------------+------+------+-----+-----+--------------+---------+---------+-------------+-----------+-------------+------------+---------+-----------------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading dataset to PySpark\n",
    "sales = spark.read.csv('/Users/mac/Documents/Hacktiv8/M3/p2-coda001-rmt-m3-mirzasjarief/us_store_sales.csv', header=True, inferSchema=True)\n",
    "sales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selanjutnya adalah load dataset menggunakan  PySpark untuk proses transformasi data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proses transform 1 \n",
    "\n",
    "- Mengubah angka negatif pada Column Inventory menjadi 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute code for replacing negative value with 0 in pyspark\n",
    "sales = sales.withColumn('Inventory', when(col('Inventory') < 0 , 0 ).otherwise(col('Inventory')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code mengecek apakah nilai dalam kolom Inventory lebih kecil dari 0.\n",
    "Jika ya, maka nilai tersebut akan diganti dengan 0. Namun jika tidak memenuhi kondisi, maka akan tetap menggunakan nilai asli dari kolom Inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|        Inventory|\n",
      "+-------+-----------------+\n",
      "|  count|             4248|\n",
      "|   mean|769.1153483992467|\n",
      "| stddev|610.0801048043983|\n",
      "|    min|              0.0|\n",
      "|    max|           8252.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check minimum value of inventory\n",
    "sales[['Inventory']].describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sekali lagi memastikan minimun data dari inventory sudah 0, karena logikanya saat stok habis nilai inventaris seharusnya menjadi nol, bukan menjadi negatif, ini bertujuan untuk menghindari analisa dan pengambilan keputusan yang salah pada penelitian lanjutan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proses transform 2\n",
    "\n",
    "- Mengubah tipe data pada **Column Date**, dan **Inventory**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               Date|\n",
      "+-------------------+\n",
      "|2010-01-04 00:00:00|\n",
      "|2010-01-07 00:00:00|\n",
      "|2010-01-11 00:00:00|\n",
      "|2010-01-12 00:00:00|\n",
      "|2011-01-07 00:00:00|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Computing convert object to timestamp\n",
    "sales = sales.withColumn('Date', to_timestamp('Date','dd/MM/yy HH:mm:ss'))\n",
    "\n",
    "sales[['Date']].show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pertama adalah merubah tipe data object pada column date menjadi tipe data time stamp, dengan tujuan menyamakan bentuk index karena apabila langsung di convert ke dalam bentuk date maka code akan error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      Date|\n",
      "+----------+\n",
      "|2010-01-04|\n",
      "|2010-01-07|\n",
      "|2010-01-11|\n",
      "|2010-01-12|\n",
      "|2011-01-07|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Computing convert timestamp to date\n",
    "\n",
    "sales = sales.withColumn(\"Date\", to_date(\"Date\", \"yyyy-MM-dd\"))\n",
    "\n",
    "sales[['Date']].show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Karena pada keterangan jam menit dan detik kosong (00:00:00), maka agar tidak menyebabkan hal yang ambigu dan menyebabkan error, seperti contohnya ketika proses load ke PostgresSQL maka tipe data timestamps akan diubah kedalam bentuk date / tanggal saja. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proses transform 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------------+-----+-----+--------------+---------+---------+-------------+-----------+-------------+------------+---------+----------+------------+-------+\n",
      "|      State|Market| Market Size|Sales| COGS|Total Expenses|Marketing|Inventory|Budget Profit|Budget COGS|Budget Margin|Budget Sales|ProductId|      Date|Product Type|   Type|\n",
      "+-----------+------+------------+-----+-----+--------------+---------+---------+-------------+-----------+-------------+------------+---------+----------+------------+-------+\n",
      "|Connecticut|  East|Small Market|292.0|116.0|          69.0|     38.0|    962.0|        110.0|      110.0|        160.0|       270.0|        2|2010-01-04|      Coffee|Regular|\n",
      "|Connecticut|  East|Small Market|225.0| 90.0|          60.0|     29.0|   1148.0|         90.0|       80.0|        130.0|       210.0|        2|2010-01-07|      Coffee|Regular|\n",
      "|Connecticut|  East|Small Market|325.0|130.0|          73.0|     42.0|   1134.0|        130.0|      110.0|        180.0|       290.0|        2|2010-01-11|      Coffee|Regular|\n",
      "+-----------+------+------------+-----+-----+--------------+---------+---------+-------------+-----------+-------------+------------+---------+----------+------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Computing column drop\n",
    "sales = sales.drop('Area Code','Product','Margin','Profit')\n",
    "\n",
    "sales.show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Drop Column Area Code, Product, Margin, Profit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proses transform 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------------+------------+-------+\n",
      "|      State|Market| Market Size|Product Type|   Type|\n",
      "+-----------+------+------------+------------+-------+\n",
      "|connecticut|  east|small market|      coffee|regular|\n",
      "|connecticut|  east|small market|      coffee|regular|\n",
      "|connecticut|  east|small market|      coffee|regular|\n",
      "|connecticut|  east|small market|      coffee|regular|\n",
      "|connecticut|  east|small market|      coffee|regular|\n",
      "+-----------+------+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert capital to lower case\n",
    "sales = (\n",
    "    sales\n",
    "    .withColumn('State', lower(col('State')))\n",
    "    .withColumn('Market', lower(col('Market')))\n",
    "    .withColumn('Market Size', lower(col('Market Size')))\n",
    "    .withColumn('Product Type', lower(col('Product Type')))\n",
    "    .withColumn('Type', lower(col('Type'))))\n",
    "\n",
    "sales[['State','Market','Market Size','Product Type','Type']].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Mengubah huruf kalimat pada index tiap kolom yang bertipe object, memastikan agar data lebih konsisten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proses transform 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------------+-----+-----+--------------+---------+---------+-------------+-----------+-------------+------------+----------+----------+------------+-------+\n",
      "|      state|market| market_size|sales| cogs|total_expenses|marketing|inventory|budget_profit|budget_cogs|budget_margin|budget_sales|product_id|      date|product_type|   type|\n",
      "+-----------+------+------------+-----+-----+--------------+---------+---------+-------------+-----------+-------------+------------+----------+----------+------------+-------+\n",
      "|connecticut|  east|small market|292.0|116.0|          69.0|     38.0|    962.0|        110.0|      110.0|        160.0|       270.0|         2|2010-01-04|      coffee|regular|\n",
      "|connecticut|  east|small market|225.0| 90.0|          60.0|     29.0|   1148.0|         90.0|       80.0|        130.0|       210.0|         2|2010-01-07|      coffee|regular|\n",
      "|connecticut|  east|small market|325.0|130.0|          73.0|     42.0|   1134.0|        130.0|      110.0|        180.0|       290.0|         2|2010-01-11|      coffee|regular|\n",
      "|connecticut|  east|small market|289.0|115.0|          69.0|     37.0|   1166.0|        110.0|      100.0|        160.0|       260.0|         2|2010-01-12|      coffee|regular|\n",
      "|connecticut|  east|small market|223.0| 90.0|          56.0|     29.0|   1148.0|         90.0|       80.0|        130.0|       210.0|         2|2011-01-07|      coffee|regular|\n",
      "+-----------+------+------------+-----+-----+--------------+---------+---------+-------------+-----------+-------------+------------+----------+----------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Converting column title from mix to lower case\n",
    "sales = (\n",
    "    sales\n",
    "    .withColumnRenamed(\"State\", \"state\")\n",
    "    .withColumnRenamed(\"Market\", \"market\")\n",
    "    .withColumnRenamed(\"Market Size\", \"market_size\")\n",
    "    .withColumnRenamed(\"Sales\", \"sales\")\n",
    "    .withColumnRenamed(\"COGS\", \"cogs\")\n",
    "    .withColumnRenamed(\"Total Expenses\", \"total_expenses\")\n",
    "    .withColumnRenamed(\"Marketing\", \"marketing\")\n",
    "    .withColumnRenamed(\"Inventory\", \"inventory\")\n",
    "    .withColumnRenamed(\"Budget Profit\", \"budget_profit\")\n",
    "    .withColumnRenamed(\"Budget COGS\", \"budget_cogs\")\n",
    "    .withColumnRenamed(\"Budget Margin\", \"budget_margin\")\n",
    "    .withColumnRenamed(\"Budget Sales\", \"budget_sales\")\n",
    "    .withColumnRenamed(\"ProductId\", \"product_id\")\n",
    "    .withColumnRenamed(\"Date\", \"date\")\n",
    "    .withColumnRenamed(\"Product Type\", \"product_type\")\n",
    "    .withColumnRenamed(\"Type\", \"type\"))\n",
    "\n",
    "\n",
    "sales.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fungsi merubah huruf kapital menjadi small letter dan mengganti spasi dengan underscore pada nama column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proses transform 6\n",
    "- Menggabungkan beberapa kolom untuk membuat table baru yang berisi unique value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|purchased_id|\n",
      "+------------+\n",
      "|   491458380|\n",
      "|  1738729669|\n",
      "|  1041025097|\n",
      "|   366943985|\n",
      "|  1130897045|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Computing new unique value column\n",
    "sales = sales.withColumn (\n",
    "    'purchased_id', abs(hash(concat_ws('',col('sales').cast('string'),col('cogs').cast('string'),col('inventory').cast('string'),monotonically_increasing_id().cast('string') )))\n",
    "    )\n",
    "\n",
    "sales[['purchased_id']].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Terakhir adalah proses menambahkan column baru yang merupakan gabungan antara sales.cogs, dan inventory menjadi kode unik untuk menandakan setiap transaksi penjualan dengan nama column **purchased_id**, dengan tujuan untuk memenuhi kriteria validasi data yang memerlukan column dengan unique value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
